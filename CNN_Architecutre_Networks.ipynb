{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RPWk_rOiCyp8"
   },
   "source": [
    "# CNN Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cofz-STHCyp9"
   },
   "source": [
    "## 1. VGG (Visual Geometry Group)\n",
    "\n",
    "Key points:\n",
    "-  With Each Conv Layer increase the number of Filters used ie if used 16filters in 1st layer,use 16 or more filters in second layer\n",
    "-  In VGG mostly 3* 3 are used , as it is cheaper to use then 5 * 5 filters and covers most of area\n",
    "\n",
    "\n",
    "![vgg](vgg_cropped.png \"VGG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "48Z9vQNQCyp-"
   },
   "source": [
    "### Creating Custom VGG in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7lqvDmWCyp_"
   },
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import Flatten, Activation,Input,BatchNormalization,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22ph7cgQCyqB",
    "outputId": "2331162b-cb3b-4d44-c712-3a733a0a259a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 1,186,378\n",
      "Trainable params: 1,186,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_vgg=Sequential(name='VGG')\n",
    "custom_vgg.add(Conv2D(64,(3,3),strides=1,padding='same',activation='relu',input_shape=(32,32,3)))\n",
    "custom_vgg.add(Dropout(0.4))\n",
    "custom_vgg.add(Conv2D(64,(3,3),strides=1,padding='same',activation='relu'))\n",
    "custom_vgg.add(Dropout(0.4))\n",
    "custom_vgg.add(MaxPooling2D((2,2)))\n",
    "\n",
    "custom_vgg.add(Conv2D(128,(3,3),strides=1,padding='same',activation='relu'))\n",
    "custom_vgg.add(Dropout(0.4))\n",
    "custom_vgg.add(Conv2D(128,(3,3),strides=1,padding='same',activation='relu'))\n",
    "custom_vgg.add(Dropout(0.4))\n",
    "custom_vgg.add(MaxPooling2D((2,2)))\n",
    "\n",
    "custom_vgg.add(Conv2D(256,(3,3),strides=1,padding='same',activation='relu'))\n",
    "custom_vgg.add(Dropout(0.4))\n",
    "custom_vgg.add(Conv2D(256,(3,3),strides=1,padding='same',activation='relu'))\n",
    "custom_vgg.add(Dropout(0.4))\n",
    "custom_vgg.add(MaxPooling2D((2,2)))\n",
    "\n",
    "custom_vgg.add(Flatten())\n",
    "custom_vgg.add(Dense(10,activation='softmax'))\n",
    "\n",
    "custom_vgg.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "custom_vgg.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70JW_DQnCyqF"
   },
   "source": [
    "-  **Cannot Create Deeper Architectures using vgg due \"Vanishing gradient Problem\"**\n",
    "-  Useful for Transfer Learning and Small Classification tasks\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZcahQ6NSCyqG"
   },
   "source": [
    "## 2. ResNet ( Residual Network )\n",
    "\n",
    "Key Points :\n",
    " - First Deep Layer Network with 152 Layers\n",
    " - **Connects current layer with previous layer as well as layer behind previous layer**\n",
    " \n",
    "In VGG, every layer is connected to its previous layer, from which it is getting its inputs. This makes sure that upon propagation from layer to layer, more and more useful features are carried and less important features are dropped out. This is not the best way since the latter layers cannot see what the former layers have seen\n",
    "\n",
    "![](resnet.png \"Resnet\")\n",
    "<br>\n",
    "<br>\n",
    "**The core idea is, let us consider x as an output of some Conv2D layer.**\n",
    "**Add few Conv2D layers to x and then add the output to x and send this as input to the next layer**\n",
    "\n",
    "![](resnet2.png \"resnet\")\n",
    "<br>\n",
    "#### x = x + conv2d ===> next layer\n",
    "<br>\n",
    "\n",
    "**Training of such a deep Residual Networks is possible by using BatchNormalisation layers after every Convolutional Layer. Batch Normalisation layers will boost the values of weights and hence higher learning rates can be used while training, which will help train faster and also can minimize Vanishing Gradient problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-svHx6ClCyqH"
   },
   "source": [
    "### Creating Custom Resnet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wP3Jl-cICyqI"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,BatchNormalization,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSP7CgUzCyqL"
   },
   "outputs": [],
   "source": [
    "stride=1\n",
    "channel_axis=3\n",
    "\n",
    "def res_layer(x,filters,pooling=False,dropout=0.0):\n",
    "    temp=x\n",
    "    temp=Conv2D(filters,(3,3),strides=stride,padding='same')(temp)\n",
    "    temp=BatchNormalization(axis=channel_axis)(temp)\n",
    "    temp=Activation('relu')(temp)\n",
    "    temp=Conv2D(filters,(3,3),strides=stride,padding='same')(temp)\n",
    "    \n",
    "    x=add([temp,Conv2D(filters,(3,3),strides=stride,padding='same')(x)])\n",
    "    \n",
    "    if pooling:\n",
    "        x=MaxPooling2D((2,2))(x)\n",
    "    if dropout!=0.0:\n",
    "        x=Dropout(dropout)(x)\n",
    "    x=BatchNormalization(axis=channel_axis)(x)\n",
    "    x=Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4zrkMcACyqN"
   },
   "source": [
    "And the process is, it connects the input layer to a Conv2D layer having filters specified in our function calling and then attaches a BatchNormalization layer, upon which a ReLU Activation layer is added, and then another Conv2D layer is stacked. Now, this stacked output is added with the initial input, but the initial input is transformed by passing it through a Conv2D layer of given filters. This step is done to match the output sizes of both the layers that are going to be added. Then, if we prefer having a MaxPooling2D layer, we add that and also if any Dropout value is given, then a Dropout layer is also added and then finally one more BatchNormalization layer and Activation layer are added and then this final layer is returned by our res_layer function.\n",
    "\n",
    "\n",
    "![](resnet3.png 'resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynQXalaLCyqO",
    "outputId": "d525dc4f-59c6-4bd1-ab2e-f14cefd7ab7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 16)   448         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 16)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 32)   4640        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 32)   128         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 32, 32)   9248        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 32, 32, 32)   4640        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 32)   0           conv2d_44[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 32, 32, 32)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 32)   128         dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 32, 32, 32)   9248        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 32)   128         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 32, 32, 32)   9248        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 32, 32, 32)   9248        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 32)   0           conv2d_47[0][0]                  \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 32, 32, 32)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 32)   128         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 32)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 32, 32, 32)   9248        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 32)   128         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 32)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 32, 32, 32)   9248        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 32, 32)   9248        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 32)   0           conv2d_50[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 32)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 32)   0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 64)   18496       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 64)   256         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 64)   36928       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 64)   18496       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 64)   0           conv2d_53[0][0]                  \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 64)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   256         dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 64)   36928       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 64)   256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 64)   36928       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 64)   36928       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 64)   0           conv2d_56[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 8, 8, 64)     0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 8, 8, 64)     0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 64)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 256)    147712      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 256)    1024        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 256)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 256)    590080      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 256)    147712      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 256)    0           conv2d_59[0][0]                  \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 8, 8, 256)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 256)    1024        dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 256)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 16384)        0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 16384)        0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4096)         67112960    dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 4096)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 100)          409700      dropout_28[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 68,671,236\n",
      "Trainable params: 68,669,284\n",
      "Non-trainable params: 1,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp=Input(shape=(32,32,3))\n",
    "x=inp\n",
    "x=Conv2D(16,(3,3),strides=stride,padding='same')(x)\n",
    "x=BatchNormalization(axis=channel_axis)(x)\n",
    "x=Activation('relu')(x)\n",
    "\n",
    "x=res_layer(x,32,dropout=0.2)\n",
    "x=res_layer(x,32,dropout=0.3)\n",
    "x=res_layer(x,32,dropout=0.4,pooling=True)\n",
    "x=res_layer(x,64,dropout=0.2)\n",
    "x=res_layer(x,64,dropout=0.2,pooling=True)\n",
    "x=res_layer(x,256,dropout=0.4)\n",
    "x=Flatten()(x)\n",
    "x=Dropout(0.4)(x)\n",
    "x=Dense(4096,activation='relu')(x)\n",
    "x=Dropout(0.23)(x)\n",
    "x=Dense(100,activation='softmax')(x)\n",
    "\n",
    "resnet_model=Model(inp,x,name='Resnet')\n",
    "resnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrl5twUECyqR"
   },
   "source": [
    "## 3. Dense Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eO2UbHx6CyqR"
   },
   "source": [
    "In ResNet, we added the stacked layer along with its input layer. <br>**In DenseNet, for a given layer, all other layers preceding to it are concatenated and given as input to the current layer.**<br> With such an arrangement, we can use smaller filter counts and also, this will minimize the vanishing gradient problem as all layers are directly connected to the output, gradients can be calculated directly from the output for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKJVpindDPEN"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from keras.layers import concatenate,Input,BatchNormalization,Dense,Conv2D,Flatten,add,Activation,MaxPooling2D,Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cw2Ii6Y8Eq6L"
   },
   "source": [
    "### Creating Custom Dense Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wWjJXJ41CyqS"
   },
   "outputs": [],
   "source": [
    "def dense_layer(x, layer_configs):\n",
    "    layers=[]\n",
    "\n",
    "    for i in range(2):\n",
    "        if layer_configs[i][\"layer_type\"] == \"Conv2D\":\n",
    "            layer = Conv2D(layer_configs[i][\"filters\"], layer_configs[i][\"kernel_size\"], strides = layer_configs[i][\"strides\"], padding = layer_configs[i][\"padding\"], activation = layer_configs[i][\"activation\"])(x)\n",
    "        layers.append(layer)\n",
    "\n",
    "    for n in range(2, len(layer_configs)):\n",
    "        if layer_configs[n][\"layer_type\"] == \"Conv2D\":\n",
    "            layer = Conv2D(layer_configs[n][\"filters\"], layer_configs[n][\"kernel_size\"], strides = layer_configs[n][\"strides\"], padding = layer_configs[n][\"padding\"], activation = layer_configs[n][\"activation\"])(concatenate(layers, axis = 3))\n",
    "        layers.append(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dV4nvs9QCyqU"
   },
   "outputs": [],
   "source": [
    "\n",
    "layer_f8 = [{\"layer_type\" : \"Conv2D\", \"filters\" : 8, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 8, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 8, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 8, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 8, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"}]\n",
    "\n",
    "\n",
    "layer_f16 =  [{\"layer_type\" : \"Conv2D\", \"filters\" : 16, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 16, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 16, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 16, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 16, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"}]\n",
    "\n",
    "\n",
    "layer_f32 =  [{\"layer_type\" : \"Conv2D\", \"filters\" : 32, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 32, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 32, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 32, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 32, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"}]\n",
    "\n",
    "\n",
    "\n",
    "layer_f64 = [{\"layer_type\" : \"Conv2D\", \"filters\" : 64, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 64, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 64, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 64, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 64, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"}]\n",
    "\n",
    "\n",
    "\n",
    "layer_f128 =  [{\"layer_type\" : \"Conv2D\", \"filters\" : 128, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 128, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 128, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 128, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "            {\"layer_type\" : \"Conv2D\", \"filters\" : 128, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9IhfJgSPCyqX",
    "outputId": "dc8eaca2-6d75-4d3c-af67-8c8c9d74a1cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 32, 32, 4)    112         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 32, 32, 8)    296         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 32, 32, 8)    296         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 32, 32, 16)   0           conv2d_56[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 32, 8)    1160        concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 32, 32, 24)   0           conv2d_56[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 32, 32, 8)    1736        concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 32, 32, 32)   0           conv2d_56[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 32, 32, 8)    2312        concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 32, 8)    0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 8)    32          dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 32, 32, 16)   1168        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 32, 16)   1168        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 32, 32, 32)   0           conv2d_61[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 32, 16)   4624        concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 32, 32, 48)   0           conv2d_61[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 32, 32, 16)   6928        concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 32, 32, 64)   0           conv2d_61[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 32, 32, 16)   9232        concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 32, 32, 16)   0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 32, 32, 32)   4640        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 32, 32, 32)   4640        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 32, 32, 64)   0           conv2d_66[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 32, 32, 32)   18464       concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 32, 32, 96)   0           conv2d_66[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "                                                                 conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 32)   27680       concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 32, 32, 128)  0           conv2d_66[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "                                                                 conv2d_68[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 32)   36896       concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 32, 32)   0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 32)   128         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 32, 32, 64)   18496       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 32, 32, 64)   18496       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 32, 32, 128)  0           conv2d_71[0][0]                  \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 32, 32, 64)   73792       concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 32, 32, 192)  0           conv2d_71[0][0]                  \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 32, 32, 64)   110656      concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 32, 32, 256)  0           conv2d_71[0][0]                  \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "                                                                 conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 32, 32, 64)   147520      concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 64)   0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 64)   256         dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 32, 32, 128)  73856       batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 32, 32, 128)  73856       batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 32, 32, 256)  0           conv2d_76[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 32, 32, 384)  0           conv2d_76[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "                                                                 conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 128)  442496      concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 32, 32, 512)  0           conv2d_76[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "                                                                 conv2d_78[0][0]                  \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 128)  589952      concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 32, 32, 128)  0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 128)  0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 128)  512         max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 16, 16, 96)   12384       batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 96)   384         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 96)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 96)     384         max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 6144)         0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 6144)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 14)           86030       dropout_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,065,686\n",
      "Trainable params: 2,064,806\n",
      "Non-trainable params: 880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp=Input((32,32,3))\n",
    "x=inp\n",
    "x = Conv2D(4, (3, 3), strides=1, padding=\"same\", activation =\"relu\")(x)\n",
    "x = dense_layer(x, layer_f8)\n",
    "x = Dropout(0.8)(x)\n",
    "\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "x = dense_layer(x, layer_f16)\n",
    "x = Dropout(0.8)(x)\n",
    "\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "x = dense_layer(x, layer_f32)\n",
    "x = Dropout(0.8)(x)\n",
    "\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "x = dense_layer(x, layer_f64)\n",
    "x = Dropout(0.8)(x)\n",
    "\n",
    "\n",
    "\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "x = dense_layer(x, layer_f128)\n",
    "x = Dropout(0.8)(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "x = Conv2D(96, (1, 1), activation = \"relu\")(x)\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "\n",
    "\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(14, activation = \"softmax\")(x)\n",
    "\n",
    "\n",
    "\n",
    "dense_net = Model(inp, x,name='DenseNet')\n",
    "\n",
    "dense_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uQOjrUbEJMF"
   },
   "source": [
    "## 4. Inception Net\n",
    "- In ResNet, we created deeper networks. The idea of Inception Net is to make the network wider. This can be done by parallel connection of multiple layers having different filters, and then finally concatenating all of those parallel paths to pass to next layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-6BFpqOCyqZ"
   },
   "outputs": [],
   "source": [
    "from keras.layers import AveragePooling2D\n",
    "def inception_layer(x, layer_configs):\n",
    "  layers = []\n",
    "\n",
    "  for configs in layer_configs:\n",
    "    if configs[0][\"layer_type\"] == \"Conv2D\":\n",
    "      layer = Conv2D(configs[0][\"filters\"], configs[0][\"kernel_size\"], strides = configs[0][\"strides\"], padding = configs[0][\"padding\"], activation = configs[0][\"activation\"])(x)\n",
    "\n",
    "    if configs[0][\"layer_type\"] == \"MaxPooling2D\":\n",
    "      layer = MaxPooling2D(configs[0][\"kernel_size\"], strides = configs[0][\"strides\"], padding = configs[0][\"padding\"])(x)\n",
    "\n",
    "    for n in range(1, len(configs)):\n",
    "      if configs[n][\"layer_type\"] == \"Conv2D\":\n",
    "        layer = Conv2D(configs[n][\"filters\"], configs[n][\"kernel_size\"], strides = configs[n][\"strides\"], padding = configs[n][\"padding\"], activation = configs[n][\"activation\"])(layer)\n",
    "\n",
    "      if configs[n][\"layer_type\"] == \"MaxPooling2D\":\n",
    "        layer = MaxPooling2D(configs[n][\"kernel_size\"], strides = configs[n][\"strides\"], padding = configs[n][\"padding\"])(layer)\n",
    "\n",
    "    layers.append(layer)\n",
    "\n",
    "  return concatenate(layers, axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XlUgt_qCyqb"
   },
   "outputs": [],
   "source": [
    "layer_3a = [[{\"layer_type\" : \"Conv2D\", \"filters\" : 64, \"kernel_size\" : (1, 1), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"}],\n",
    "[{\"layer_type\" : \"Conv2D\", \"filters\" : 96, \"kernel_size\" : (1, 1), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "{\"layer_type\" : \"Conv2D\", \"filters\" : 128, \"kernel_size\" : (3, 3), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"}],\n",
    "[{\"layer_type\" : \"Conv2D\", \"filters\" : 16, \"kernel_size\" : (1, 1), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"},\n",
    "{\"layer_type\" : \"Conv2D\", \"filters\" : 32, \"kernel_size\" : (5, 5), \"strides\" : 1, \"padding\" : \"same\", \"activation\" : \"relu\"}],\n",
    "[{\"layer_type\" : \"MaxPooling2D\",\"strides\" : 1,\"kernel_size\" : (3, 3),\"padding\" : \"same\"},\n",
    "{\"layer_type\" : \"Conv2D\",\"filters\" : 32,\"kernel_size\" : (1, 1),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"}]]\n",
    "\n",
    "\n",
    "\n",
    "layer_3b = [[{\"layer_type\" : \"Conv2D\",\"filters\" : 128,\"kernel_size\" : (1, 1),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\" }],\n",
    "[{ \"layer_type\" : \"Conv2D\",\"filters\" : 128,\"kernel_size\" : (1, 1),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\" },\n",
    "{\"layer_type\" : \"Conv2D\",\"filters\" : 192,\"kernel_size\" : (3, 3),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"}],\n",
    "[{\"layer_type\" : \"Conv2D\",\"filters\" : 32,\"kernel_size\" : (1, 1),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"},\n",
    "{\"layer_type\" : \"Conv2D\",\"filters\" : 96,\"kernel_size\" : (5, 5),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\" }],\n",
    "[{\"layer_type\" : \"MaxPooling2D\",\"strides\" : 1,\"kernel_size\" : (3, 3),\"padding\" : \"same\"},\n",
    "{\"layer_type\" : \"Conv2D\",\"filters\" : 96,\"kernel_size\" : (1, 1),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"}]]\n",
    "\n",
    "\n",
    "\n",
    "layer_4a = [[{\"layer_type\" : \"Conv2D\",\"filters\" : 192,\"kernel_size\" : (1, 1),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"}],\n",
    "[{\"layer_type\" : \"Conv2D\",\"filters\" : 96,\"kernel_size\" : (1, 1),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"},\n",
    "{\"layer_type\" : \"Conv2D\",\"filters\" : 208,\"kernel_size\" : (3, 3),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"}],\n",
    "[{\"layer_type\" : \"Conv2D\",\"filters\" : 16,\"kernel_size\" : (1, 1),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"},\n",
    "{\"layer_type\" : \"Conv2D\",\"filters\" : 48,\"kernel_size\" : (5, 5),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"}],\n",
    "[{\"layer_type\" : \"MaxPooling2D\",\"strides\" : 1,\"kernel_size\" : (3, 3),\"padding\" : \"same\"},\n",
    "{\"layer_type\" : \"Conv2D\",\"filters\" : 64,\"kernel_size\" : (1, 1),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"}]]\n",
    "\n",
    "\n",
    "\n",
    "layer_4b = [[{\"layer_type\" : \"Conv2D\",\"filters\" : 160,\"kernel_size\" : (1, 1),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"}],\n",
    "[{\"layer_type\" : \"Conv2D\",\"filters\" : 112,\"kernel_size\" : (1, 1),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"},\n",
    "{\"layer_type\" : \"Conv2D\",\"filters\" : 224,\"kernel_size\" : (3, 3),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"}],\n",
    "[{\"layer_type\" : \"Conv2D\",\"filters\" : 24,\"kernel_size\" : (1, 1),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"},\n",
    "{\"layer_type\" : \"Conv2D\",\"filters\" : 64,\"kernel_size\" : (5, 5),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"}],\n",
    "[{\"layer_type\" : \"MaxPooling2D\",\"strides\" : 1,\"kernel_size\" : (3, 3),\"padding\" : \"same\"},\n",
    "{\"layer_type\" : \"Conv2D\",\"filters\" : 64,\"kernel_size\" : (1, 1),\"strides\" : 1,\"padding\" : \"same\",\"activation\" : \"relu\"}]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nPaFYxneLRov",
    "outputId": "20681ca0-4e02-4c21-939e-639598f10fa9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0828 03:04:36.163210 139641907955584 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 64)   9472        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 8, 8, 64)     0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 8, 8, 64)     4160        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 8, 8, 192)    110784      conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 4, 4, 192)    0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 4, 4, 96)     18528       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 4, 4, 16)     3088        max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 4, 4, 192)    0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 4, 4, 64)     12352       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 4, 4, 128)    110720      conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 4, 4, 32)     12832       conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 4, 4, 32)     6176        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 4, 4, 256)    0           conv2d_106[0][0]                 \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "                                                                 conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 4, 4, 128)    32896       concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 4, 4, 32)     8224        concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 4, 4, 256)    0           concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 4, 4, 128)    32896       concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 4, 4, 192)    221376      conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 4, 4, 96)     76896       conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 4, 4, 96)     24672       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 4, 4, 512)    0           conv2d_112[0][0]                 \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "                                                                 conv2d_116[0][0]                 \n",
      "                                                                 conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 2, 2, 512)    0           concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 2, 2, 96)     49248       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 2, 2, 16)     8208        max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 2, 2, 512)    0           max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 2, 2, 192)    98496       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 2, 2, 208)    179920      conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 2, 2, 48)     19248       conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 2, 2, 64)     32832       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 2, 2, 512)    0           conv2d_118[0][0]                 \n",
      "                                                                 conv2d_120[0][0]                 \n",
      "                                                                 conv2d_122[0][0]                 \n",
      "                                                                 conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 1, 1, 128)    65664       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 128)          0           conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         132096      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 1024)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 100)          102500      dropout_19[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,373,284\n",
      "Trainable params: 1,373,284\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inp = Input(shape = (32, 32, 3))\n",
    "\n",
    "x = inp\n",
    "\n",
    "x = Conv2D(64, (7, 7), strides = 2, padding = \"same\", activation = \"relu\")(x)\n",
    "\n",
    "x = MaxPooling2D((3, 3), padding = \"same\", strides = 2)(x)\n",
    "\n",
    "x = Conv2D(64, (1, 1), strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "\n",
    "x = Conv2D(192, (3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "\n",
    "x = MaxPooling2D((3, 3), padding = \"same\", strides = 2)(x)\n",
    "\n",
    "x = inception_layer(x, layer_3a)\n",
    "\n",
    "x = inception_layer(x, layer_3b)\n",
    "\n",
    "x = MaxPooling2D((3, 3), padding = \"same\", strides = 2)(x)\n",
    "\n",
    "x = inception_layer(x, layer_4a)\n",
    "\n",
    "\n",
    "\n",
    "x1 = AveragePooling2D((2, 2), strides = 3)(x)\n",
    "\n",
    "x1 = Conv2D(128, (1, 1), padding = \"same\", activation = \"relu\")(x1)\n",
    "\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "x1 = Dense(1024, activation = \"relu\")(x1)\n",
    "\n",
    "x1 = Dropout(0.7)(x1)\n",
    "\n",
    "x1 = Dense(100, activation = \"softmax\")(x1)\n",
    "\n",
    "\n",
    "\n",
    "inc = Model(inp, x1)\n",
    "\n",
    "inc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ag0-Mj0DL3Ju"
   },
   "source": [
    "There are many variants of Inception Nets. The differences among them are:<br>\n",
    "- Instead of using a 5*5 filter, use two 3*3 filters as they are computationally efficient (as discussed in the VGGNet).\n",
    "- Using a 1 * 1 Conv2D layer with smaller filter count before performing any Conv2D layer with larger filter sizes as 1 * 1 filter with less filter count will reduce the depth of the input and hence is computationally efficient.\n",
    "-  Instead of performing a 3 *  3 filter, perform 1 * 3 filter followed by a 3 * 1 filter. This will drastically improve the computational efficiency.\n",
    "\n",
    "**InceptionNets are preferable as they are not just deeper, but also wider and we can stack many such layers and still the output params to be trained are less when compared to all other architectures.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9zRNoL-1NCnD"
   },
   "source": [
    "## 5. Xception Net\n",
    "- Xception Net is an improvisation of InceptionNet in terms of computational efficiency. Xception means Extreme Inception\n",
    "\n",
    "- Xception Net outperforms Inception Net v3\n",
    "\n",
    "- In Inception Net normal convolutional operations are performed whereas in Xception Net, Depthwise Separable Convolutional operations are performed.\n",
    "- In Depthwise separable convolutions, each channel have only one kernel to do convolution. Hence, by performing Depthwise Separable Convolutions, we can reduce the **computational complexity** as every kernel is of two dimensional only and is convoluting only over one channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7oGBPUg-LZ9l",
    "outputId": "3cc4fd74-1703-453e-8dce-9ac6b1992ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 16, 16, 32)   896         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 16, 16, 64)   18496       dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16, 16, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 64)   256         dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_1 (DepthwiseCo (None, 16, 16, 64)   640         dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   256         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_2 (DepthwiseCo (None, 16, 16, 64)   640         depthwise_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 15, 15, 64)   0           depthwise_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 15, 15, 64)   16448       dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 15, 15, 128)  0           max_pooling2d_19[0][0]           \n",
      "                                                                 conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 15, 15, 128)  512         concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 15, 15, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 15, 15, 128)  0           concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 15, 15, 128)  512         dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 15, 15, 256)  295168      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 15, 15, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_3 (DepthwiseCo (None, 15, 15, 256)  2560        conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 15, 15, 128)  512         dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_4 (DepthwiseCo (None, 15, 15, 256)  2560        depthwise_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 15, 15, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 14, 14, 256)  0           depthwise_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 14, 14, 256)  131328      dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 14, 14, 512)  0           max_pooling2d_20[0][0]           \n",
      "                                                                 conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 14, 14, 512)  0           concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 14, 14, 256)  1179904     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 14, 14, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 14, 14, 128)  295040      dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 128)  512         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 14, 14, 128)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 25088)        0           dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 100)          2508900     flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,456,548\n",
      "Trainable params: 4,454,564\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import DepthwiseConv2D\n",
    "inp = Input(shape = (32, 32, 3))\n",
    "\n",
    "x = inp\n",
    "\n",
    "x = Conv2D(32, (3, 3), strides = 2, padding = \"same\", activation = \"relu\")(x)\n",
    "\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "x = Conv2D(64, (3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "\n",
    "\n",
    "x1 = DepthwiseConv2D((3, 3), (1, 1), padding = \"same\", activation = \"relu\")(x)\n",
    "\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x1 = DepthwiseConv2D((3, 3), (1, 1), padding = \"same\", activation = \"relu\")(x1)\n",
    "\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x1 = MaxPooling2D((2, 2), strides = 1)(x1)\n",
    "\n",
    "\n",
    "\n",
    "x = concatenate([x1, Conv2D(64, (2, 2), strides = 1)(x)])\n",
    "\n",
    "\n",
    "\n",
    "x1 = Activation(\"relu\")(x)\n",
    "\n",
    "x1 = Conv2D(256, (3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x1)\n",
    "\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x1 = DepthwiseConv2D((3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x1)\n",
    "\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x1 = DepthwiseConv2D((3, 3), strides = 1, padding = \"same\")(x1)\n",
    "\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x1 = MaxPooling2D((2, 2), strides = 1)(x1)\n",
    "\n",
    "\n",
    "\n",
    "x = concatenate([x1, Conv2D(256, (2, 2), strides = 1)(x)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = Conv2D(256, (3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "\n",
    "x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "\n",
    "\n",
    "x = Dense(100, activation = \"softmax\")(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xception = Model(inp, x)\n",
    "\n",
    "xception.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1lDZpgC5Od6c"
   },
   "source": [
    "**We can use XceptionNet in low power devices as there are less compuations in the Conv layer and also is accuracy is pretty similar when compared to a normal convolution layer**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZcahQ6NSCyqG",
    "xrl5twUECyqR"
   ],
   "name": "CNN Architecutre Networks.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
